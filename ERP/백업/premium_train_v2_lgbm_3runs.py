# premium_train_v2_lgbm_3runs_avg.py
# -----------------------------------------
# ê¶Œë¦¬ê¸ˆ ì˜ˆì¸¡ AIëª¨ë¸ - LightGBM ê¸°ë°˜ 3íšŒ ë°˜ë³µ í•™ìŠµ ë° í‰ê·  ì†ë„ ê³„ì‚° ë²„ì „
# ê° íšŒì°¨ë³„ ì„±ëŠ¥ ë¡œê·¸ + ì „ì²´ í‰ê· ê°’ ê³„ì‚° ë° í‘œì‹œ
# -----------------------------------------

import os, time, json, joblib, numpy as np, pandas as pd, datetime
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import lightgbm as lgb

# ============================================
# ì„¤ì •
# ============================================
DATA_PATH  = r"C:\Users\awmve\OneDrive\ë°”íƒ• í™”ë©´\my_project\ì–‘ë„ì–‘ìˆ˜ë§¤ë¬¼ë¦¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (2).xlsx"
TARGET_NAME = "ê¶Œë¦¬ê¸ˆ"
TEST_SIZE = 0.2
RANDOM_STATE = 42
EPOCHS = 10
TREES_PER_EPOCH = 100
TARGET_MAE = 30_000_000
CSV_LOG = "train_speed_log_3runs.csv"
MODEL_OUT = "premium_model_v2.joblib"

# ============================================
# ë°ì´í„° ì „ì²˜ë¦¬
# ============================================
def load_table(path):
    if path.lower().endswith(".csv"):
        return pd.read_csv(path)
    return pd.read_excel(path, engine="openpyxl")

def engineer(df: pd.DataFrame):
    X = df.copy()
    if "ì „ìš©ë©´ì " in X.columns and "ì›”ì„¸" in X.columns:
        X["ì›”ì„¸_per_m2"] = X["ì›”ì„¸"] / X["ì „ìš©ë©´ì "].replace(0, np.nan)
    if "ì›”í‰ê·  ë§¤ì¶œì•¡" in X.columns and "ì›”ì„¸" in X.columns:
        X["rent_sales_ratio"] = X["ì›”ì„¸"] / X["ì›”í‰ê·  ë§¤ì¶œì•¡"].replace(0, np.nan)
    for col in ["ì „ìš©ë©´ì ","ì›”ì„¸","ë³´ì¦ê¸ˆ","ê´€ë¦¬ë¹„","ì›”í‰ê·  ë§¤ì¶œì•¡",
                "ì›”ì„¸_per_m2","rent_sales_ratio"]:
        if col in X.columns:
            X[f"log1p_{col}"] = np.log1p(pd.to_numeric(X[col], errors="coerce"))
    if "ë§¤ë§¤ ê°€ëŠ¥ ì¼ì •" in X.columns:
        order_map = {"ì¦‰ì‹œ":3,"ì¦‰ì‹œê°€ëŠ¥":3,"1~2ê°œì›”":2,"3~5ê°œì›”":1,"6~8ê°œì›”":0,"í˜‘ì˜ ê°€ëŠ¥":1,"í˜‘ì˜ê°€ëŠ¥":1}
        X["ë§¤ë§¤ ê°€ëŠ¥ ì¼ì •(ord)"] = X["ë§¤ë§¤ ê°€ëŠ¥ ì¼ì •"].map(order_map)
    return X

# ============================================
# ì†ë„ ì¸¡ì • í´ë˜ìŠ¤
# ============================================
class TrainSpeedMeter:
    def __init__(self, train_size:int, target_mae:float):
        self.train_size = train_size
        self.target_mae = target_mae
        self.start_time = None
        self.end_time = None
        self.epoch_times = []
        self.epochs = 0
        self.tta_sec = None
        self.result = {}

    def start(self):
        self.start_time = datetime.datetime.now().isoformat()
        self.t0 = time.perf_counter()

    def tick_epoch_start(self):
        self._ep_t0 = time.perf_counter()

    def tick_epoch_end(self, val_mae=None):
        elapsed = time.perf_counter() - self._ep_t0
        self.epoch_times.append(elapsed)
        self.epochs += 1
        if val_mae and val_mae <= self.target_mae and not self.tta_sec:
            self.tta_sec = time.perf_counter() - self.t0

    def finish(self, run_index:int):
        self.end_time = datetime.datetime.now().isoformat()
        total_sec = time.perf_counter() - self.t0
        sec_per_epoch = np.mean(self.epoch_times)
        samples_per_sec = (self.train_size * self.epochs) / total_sec
        sec_per_1000 = (total_sec * 1000) / (self.train_size * self.epochs)
        self.result = {
            "run_index": run_index,
            "start_time": self.start_time,
            "end_time": self.end_time,
            "total_sec": round(total_sec, 8),
            "sec_per_epoch_avg": round(sec_per_epoch, 8),
            "samples_per_sec": round(samples_per_sec, 8),
            "sec_per_1000_samples": round(sec_per_1000, 8),
            "epochs": self.epochs,
            "tta_sec": round(self.tta_sec, 8) if self.tta_sec else None,
            "target_mae": self.target_mae,
            "train_size": self.train_size
        }
        return self.result

# ============================================
# í•™ìŠµ 1íšŒ ìˆ˜í–‰ í•¨ìˆ˜
# ============================================
def train_once(run_idx:int, X_train, X_val, y_train_raw, y_val_true, cat_cols):
    print(f"\n========== [RUN {run_idx}] ì‹œì‘ ==========")
    y_train = np.log1p(y_train_raw.values.astype(float))
    dtrain = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_cols, free_raw_data=False)
    dval = lgb.Dataset(X_val, label=np.log1p(y_val_true.values.astype(float)), categorical_feature=cat_cols, free_raw_data=False)
    params = {
        "objective": "regression",
        "metric": "l1",
        "learning_rate": 0.05,
        "num_leaves": 31,
        "feature_fraction": 0.9,
        "bagging_fraction": 0.9,
        "bagging_freq": 1,
        "min_data_in_leaf": 20,
        "verbosity": -1,
        "seed": RANDOM_STATE + run_idx
    }

    meter = TrainSpeedMeter(train_size=len(X_train), target_mae=TARGET_MAE)
    meter.start()
    print(f"[SPEED] start_time = {meter.start_time}")

    booster = None
    for ep in range(EPOCHS):
        meter.tick_epoch_start()
        booster = lgb.train(params, dtrain, num_boost_round=TREES_PER_EPOCH,
                            valid_sets=[dval], init_model=booster,
                            keep_training_booster=True)
        pred = np.expm1(booster.predict(X_val))
        val_mae = float(mean_absolute_error(y_val_true, pred))
        meter.tick_epoch_end(val_mae)
        print(f"  - epoch {ep+1:02d}: iters_total={booster.current_iteration()}, val_MAE={val_mae:,.1f}")

    result = meter.finish(run_idx)
    print(f"[SPEED] end_time = {result['end_time']}")
    print("[SPEED]", json.dumps(result, ensure_ascii=False, indent=2))
    return result

# ============================================
# ë©”ì¸ ë£¨í”„ (3íšŒ ë°˜ë³µ + í‰ê·  ê³„ì‚°)
# ============================================
def main():
    df = load_table(DATA_PATH)
    print(f"[INFO] Load table: {DATA_PATH} (rows={len(df)})")
    y = pd.to_numeric(df[TARGET_NAME], errors="coerce")
    X = engineer(df.drop(columns=[TARGET_NAME]))

    cat_cols = [c for c in X.columns if X[c].dtype == 'object']
    for c in cat_cols:
        X[c] = X[c].astype("category")

    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)

    all_results = []
    for run_idx in range(1, 4):  # âœ… ì´ 3íšŒ ë°˜ë³µ
        result = train_once(run_idx, X_train, X_val, y_train, y_val, cat_cols)
        all_results.append(result)

    df_result = pd.DataFrame(all_results)

    # âœ… í‰ê·  ê³„ì‚°
    avg = df_result[['total_sec','sec_per_epoch_avg','samples_per_sec','sec_per_1000_samples','tta_sec']].mean()
    avg_row = {
        "run_index": "avg",
        "start_time": "-",
        "end_time": "-",
        "total_sec": round(avg['total_sec'], 8),
        "sec_per_epoch_avg": round(avg['sec_per_epoch_avg'], 8),
        "samples_per_sec": round(avg['samples_per_sec'], 8),
        "sec_per_1000_samples": round(avg['sec_per_1000_samples'], 8),
        "epochs": 10,
        "tta_sec": round(avg['tta_sec'], 8),
        "target_mae": TARGET_MAE,
        "train_size": len(X_train)
    }
    df_result = pd.concat([df_result, pd.DataFrame([avg_row])], ignore_index=True)

    # CSV ì €ì¥
    df_result.to_csv(CSV_LOG, index=False, encoding="utf-8-sig")

    # ì½˜ì†” í‘œì‹œ
    print("\nâœ… [3íšŒ í‰ê·  ê²°ê³¼]")
    print(f"í‰ê·  total_sec = {avg['total_sec']:.4f}ì´ˆ")
    print(f"í‰ê·  sec_per_epoch_avg = {avg['sec_per_epoch_avg']:.4f}ì´ˆ")
    print(f"í‰ê·  samples_per_sec = {avg['samples_per_sec']:.2f}ê±´/ì´ˆ")
    print(f"í‰ê·  sec_per_1000_samples = {avg['sec_per_1000_samples']:.5f}ì´ˆ/1000ê±´")
    print(f"í‰ê·  tta_sec = {avg['tta_sec']:.4f}ì´ˆ")
    print(f"\nğŸ“„ ê²°ê³¼ ì €ì¥: {CSV_LOG}")

if __name__ == "__main__":
    main()
